{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fec44fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2956207696.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pyenv install 3.11.9\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pyenv install 3.11.9\n",
    "pyenv global 3.11.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e89682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (58.1.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp39-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp39-cp39-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn-extra\n",
      "  Using cached scikit_learn_extra-0.3.0-cp39-cp39-macosx_10_9_x86_64.whl (397 kB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.13.1-cp39-cp39-macosx_10_9_x86_64.whl (39.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting Bio\n",
      "  Downloading bio-1.6.2-py3-none-any.whl (278 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from torch) (4.14.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading pillow-11.3.0-cp39-cp39-macosx_10_10_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting numpy\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp39-cp39-macosx_10_9_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting biopython>=1.80\n",
      "  Downloading biopython-1.85-cp39-cp39-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pooch\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m965.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mygene\n",
      "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting gprofiler-official\n",
      "  Downloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_10_9_universal2.whl (14 kB)\n",
      "Collecting biothings-client>=0.2.6\n",
      "  Downloading biothings_client-0.4.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pandas->Bio) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pooch->Bio) (4.3.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pooch->Bio) (25.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting httpx>=0.22.0\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.17.0)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Collecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.3.0)\n",
      "Installing collected packages: pytz, mpmath, urllib3, tzdata, tqdm, threadpoolctl, sympy, sniffio, pillow, numpy, networkx, MarkupSafe, joblib, idna, h11, fsspec, filelock, charset_normalizer, certifi, scipy, requests, pandas, jinja2, httpcore, biopython, anyio, torch, scikit-learn, pooch, httpx, gprofiler-official, torchvision, scikit-learn-extra, biothings-client, mygene, Bio\n",
      "Successfully installed Bio-1.6.2 MarkupSafe-3.0.2 anyio-4.9.0 biopython-1.85 biothings-client-0.4.1 certifi-2025.7.9 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 gprofiler-official-1.0.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jinja2-3.1.6 joblib-1.5.1 mpmath-1.3.0 mygene-3.2.2 networkx-3.2.1 numpy-2.0.2 pandas-2.3.1 pillow-11.3.0 pooch-1.8.2 pytz-2025.2 requests-2.32.4 scikit-learn-1.6.1 scikit-learn-extra-0.3.0 scipy-1.13.1 sniffio-1.3.1 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.2.2 torchvision-0.17.2 tqdm-4.67.1 tzdata-2025.2 urllib3-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install setuptools torch torchvision scikit-learn scikit-learn-extra scipy Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfea409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.17 (main, Jun 24 2025, 15:01:51) \n",
      "[Clang 16.0.0 (clang-1600.0.26.6)]\n"
     ]
    }
   ],
   "source": [
    "import setuptools\n",
    "import sys\n",
    "\n",
    "sys.modules['distutils'] = setuptools\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c01f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting d2l==0.17.5\n",
      "  Using cached d2l-0.17.5-py3-none-any.whl (82 kB)\n",
      "Installing collected packages: d2l\n",
      "Successfully installed d2l-0.17.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install d2l==0.17.5 --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b687d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement distutils (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for distutils\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install distutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc358fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'TransformerBeta_project' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/HZ3519/TransformerBeta_project.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1eee85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./TransformerBeta_project\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bertviz==1.4.0\n",
      "  Using cached bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
      "Collecting biopython==1.81\n",
      "  Using cached biopython-1.81-cp39-cp39-macosx_10_9_x86_64.whl (2.7 MB)\n",
      "Collecting matplotlib==3.5.1\n",
      "  Using cached matplotlib-3.5.1-cp39-cp39-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "Collecting numpy==1.23.0\n",
      "  Using cached numpy-1.23.0-cp39-cp39-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Collecting pandas==1.4.3\n",
      "  Using cached pandas-1.4.3-cp39-cp39-macosx_10_9_x86_64.whl (11.5 MB)\n",
      "Collecting pip-tools==6.13.0\n",
      "  Using cached pip_tools-6.13.0-py3-none-any.whl (53 kB)\n",
      "Collecting scikit-learn==1.1.3\n",
      "  Using cached scikit_learn-1.1.3-cp39-cp39-macosx_10_9_x86_64.whl (8.7 MB)\n",
      "Requirement already satisfied: scikit-learn-extra==0.3.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from -r ./TransformerBeta_project/requirements.txt (line 8)) (0.3.0)\n",
      "Collecting scipy==1.8.1\n",
      "  Using cached scipy-1.8.1-cp39-cp39-macosx_12_0_universal2.macosx_10_9_x86_64.whl (55.6 MB)\n",
      "Collecting seaborn==0.12.1\n",
      "  Using cached seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "Collecting sentencepiece==0.1.96\n",
      "  Using cached sentencepiece-0.1.96-cp39-cp39-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting torch==1.12.0\n",
      "  Using cached torch-1.12.0-cp39-none-macosx_10_9_x86_64.whl (133.6 MB)\n",
      "Collecting torchvision==0.13.0\n",
      "  Using cached torchvision-0.13.0-cp39-cp39-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "Collecting jupyter==1.0.0\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting requests==2.25.1\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.39.4-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_10_9_x86_64.whl (287 kB)\n",
      "Collecting transformers>=2.0\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from bertviz==1.4.0->-r ./TransformerBeta_project/requirements.txt (line 1)) (4.67.1)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from matplotlib==3.5.1->-r ./TransformerBeta_project/requirements.txt (line 3)) (25.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.58.5-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from matplotlib==3.5.1->-r ./TransformerBeta_project/requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from matplotlib==3.5.1->-r ./TransformerBeta_project/requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pandas==1.4.3->-r ./TransformerBeta_project/requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: setuptools in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pip-tools==6.13.0->-r ./TransformerBeta_project/requirements.txt (line 6)) (58.1.0)\n",
      "Collecting click>=8\n",
      "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Collecting build\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pip>=22.2 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from pip-tools==6.13.0->-r ./TransformerBeta_project/requirements.txt (line 6)) (23.0.1)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from scikit-learn==1.1.3->-r ./TransformerBeta_project/requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from scikit-learn==1.1.3->-r ./TransformerBeta_project/requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from torch==1.12.0->-r ./TransformerBeta_project/requirements.txt (line 12)) (4.14.1)\n",
      "Collecting jupyter-console\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Collecting qtconsole\n",
      "  Using cached qtconsole-5.6.1-py3-none-any.whl (125 kB)\n",
      "Collecting nbconvert\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (6.29.5)\n",
      "Collecting notebook\n",
      "  Downloading notebook-7.4.4-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from requests==2.25.1->-r ./TransformerBeta_project/requirements.txt (line 15)) (2025.7.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib==3.5.1->-r ./TransformerBeta_project/requirements.txt (line 3)) (1.17.0)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_10_12_x86_64.whl (436 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.22,>=0.21\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_10_12_x86_64.whl (2.9 MB)\n",
      "Requirement already satisfied: filelock in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from transformers>=2.0->bertviz==1.4.0->-r ./TransformerBeta_project/requirements.txt (line 1)) (3.18.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl (184 kB)\n",
      "Collecting botocore<1.40.0,>=1.39.4\n",
      "  Downloading botocore-1.39.4-py3-none-any.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0\n",
      "  Using cached s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Collecting tomli>=1.1.0\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from build->pip-tools==6.13.0->-r ./TransformerBeta_project/requirements.txt (line 6)) (8.7.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.1.7)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (27.0.0)\n",
      "Requirement already satisfied: appnope in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.1.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (5.14.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (5.8.1)\n",
      "Requirement already satisfied: psutil in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (7.0.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (1.8.14)\n",
      "Requirement already satisfied: nest-asyncio in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (1.6.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (6.5.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (8.6.3)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (8.18.1)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.2.2)\n",
      "Collecting jupyterlab_widgets~=3.0.15\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Collecting widgetsnbextension~=4.0.14\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (3.0.51)\n",
      "Requirement already satisfied: pygments in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyter-console->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (2.19.2)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (3.1.6)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Collecting mistune<4,>=2.0.3\n",
      "  Using cached mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from nbconvert->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (3.0.2)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting nbformat>=5.7\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Collecting bleach[css]!=5.0.0\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Collecting nbclient>=0.5.0\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting jupyterlab<4.5,>=4.4.4\n",
      "  Downloading jupyterlab-4.4.4-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-server<3,>=2.27.1\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Using cached jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Collecting qtpy>=2.4.0\n",
      "  Using cached QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=2.0->bertviz==1.4.0->-r ./TransformerBeta_project/requirements.txt (line 1)) (2025.5.1)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_10_12_x86_64.whl (2.7 MB)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from importlib-metadata>=4.6->build->pip-tools==6.13.0->-r ./TransformerBeta_project/requirements.txt (line 6)) (3.23.0)\n",
      "Requirement already satisfied: decorator in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.19.2)\n",
      "Requirement already satisfied: stack-data in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (4.3.8)\n",
      "Collecting jupyter-events>=0.11.0\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Collecting send2trash>=1.8.2\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Collecting websocket-client>=1.7\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Collecting argon2-cffi>=21.1\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting prometheus-client>=0.9\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (4.9.0)\n",
      "Collecting jupyter-server-terminals>=0.4.4\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Collecting overrides>=5.0\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jupyterlab<4.5,>=4.4.4->notebook->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.28.1)\n",
      "Collecting jupyter-lsp>=2.0.0\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Collecting async-lru>=1.0.0\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Collecting babel>=2.10\n",
      "  Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab-server<3,>=2.27.1\n",
      "  Using cached jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\n",
      "  Using cached jupyterlab_server-2.27.1-py3-none-any.whl (59 kB)\n",
      "INFO: pip is looking at multiple versions of jupyterlab to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of jupyter-server to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-server<3,>=2.4.0\n",
      "  Using cached jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-core!=5.0.*,>=4.12\n",
      "  Using cached jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "INFO: pip is looking at multiple versions of jmespath to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jinja2>=3.0\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython>=7.23.1\n",
      "  Using cached ipython-8.18.1-py3-none-any.whl (808 kB)\n",
      "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0,>=0.30.0\n",
      "  Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Using cached huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "  Using cached huggingface_hub-0.32.6-py3-none-any.whl (512 kB)\n",
      "  Using cached huggingface_hub-0.32.5-py3-none-any.whl (512 kB)\n",
      "  Using cached huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\n",
      "  Using cached huggingface_hub-0.32.3-py3-none-any.whl (512 kB)\n",
      "  Using cached huggingface_hub-0.32.2-py3-none-any.whl (509 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached huggingface_hub-0.32.1-py3-none-any.whl (509 kB)\n",
      "  Using cached huggingface_hub-0.32.0-py3-none-any.whl (509 kB)\n",
      "  Using cached huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "  Using cached huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
      "  Using cached huggingface_hub-0.31.1-py3-none-any.whl (484 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached huggingface_hub-0.31.0-py3-none-any.whl (484 kB)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "  Using cached huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "  Using cached huggingface_hub-0.30.0-py3-none-any.whl (481 kB)\n",
      "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting debugpy>=1.6.5\n",
      "  Using cached debugpy-1.8.14-cp39-cp39-macosx_14_0_x86_64.whl (2.1 MB)\n",
      "INFO: pip is looking at multiple versions of comm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting comm>=0.1.1\n",
      "  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of botocore to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of bleach[css] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting bleach[css]!=5.0.0\n",
      "  Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "INFO: pip is looking at multiple versions of wheel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "INFO: pip is looking at multiple versions of qtconsole to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting qtconsole\n",
      "  Using cached qtconsole-5.6.0-py3-none-any.whl (124 kB)\n",
      "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting notebook\n",
      "  Using cached notebook-7.4.3-py3-none-any.whl (14.3 MB)\n",
      "  Using cached notebook-7.4.2-py3-none-any.whl (14.3 MB)\n",
      "  Using cached notebook-7.4.1-py3-none-any.whl (14.3 MB)\n",
      "  Using cached notebook-7.4.0-py3-none-any.whl (14.3 MB)\n",
      "  Using cached notebook-7.3.3-py3-none-any.whl (13.1 MB)\n",
      "Collecting jupyterlab<4.4,>=4.3.6\n",
      "  Downloading jupyterlab-4.3.8-py3-none-any.whl (11.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting notebook\n",
      "  Using cached notebook-7.3.2-py3-none-any.whl (13.2 MB)\n",
      "  Using cached notebook-7.3.1-py3-none-any.whl (13.2 MB)\n",
      "INFO: pip is looking at multiple versions of notebook to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached notebook-7.3.0-py3-none-any.whl (12.9 MB)\n",
      "  Using cached notebook-7.2.3-py3-none-any.whl (5.1 MB)\n",
      "Collecting jupyterlab<4.3,>=4.2.0\n",
      "  Using cached jupyterlab-4.2.7-py3-none-any.whl (11.6 MB)\n",
      "Collecting notebook\n",
      "  Using cached notebook-7.2.2-py3-none-any.whl (5.0 MB)\n",
      "  Using cached notebook-7.2.1-py3-none-any.whl (5.0 MB)\n",
      "  Using cached notebook-7.2.0-py3-none-any.whl (5.0 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached notebook-7.1.3-py3-none-any.whl (5.0 MB)\n",
      "Collecting jupyterlab<4.2,>=4.1.1\n",
      "  Using cached jupyterlab-4.1.8-py3-none-any.whl (11.4 MB)\n",
      "Collecting jupyterlab-server<3,>=2.22.1\n",
      "  Using cached jupyterlab_server-2.27.0-py3-none-any.whl (59 kB)\n",
      "  Using cached jupyterlab_server-2.26.0-py3-none-any.whl (59 kB)\n",
      "  Using cached jupyterlab_server-2.25.4-py3-none-any.whl (58 kB)\n",
      "  Using cached jupyterlab_server-2.25.3-py3-none-any.whl (58 kB)\n",
      "  Using cached jupyterlab_server-2.25.2-py3-none-any.whl (58 kB)\n",
      "  Using cached jupyterlab_server-2.25.1-py3-none-any.whl (58 kB)\n",
      "  Using cached jupyterlab_server-2.25.0-py3-none-any.whl (57 kB)\n",
      "  Using cached jupyterlab_server-2.24.0-py3-none-any.whl (57 kB)\n",
      "  Using cached jupyterlab_server-2.23.0-py3-none-any.whl (57 kB)\n",
      "  Using cached jupyterlab_server-2.22.1-py3-none-any.whl (57 kB)\n",
      "Collecting notebook\n",
      "  Using cached notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
      "  Using cached notebook-7.1.1-py3-none-any.whl (5.0 MB)\n",
      "  Using cached notebook-7.1.0-py3-none-any.whl (5.0 MB)\n",
      "  Using cached notebook-7.0.8-py3-none-any.whl (4.0 MB)\n",
      "Collecting jupyterlab<4.1,>=4.0.2\n",
      "  Using cached jupyterlab-4.0.13-py3-none-any.whl (9.2 MB)\n",
      "Collecting notebook\n",
      "  Using cached notebook-7.0.7-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.6-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.5-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.4-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.3-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.2-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.1-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-7.0.0-py3-none-any.whl (4.0 MB)\n",
      "  Using cached notebook-6.5.7-py3-none-any.whl (529 kB)\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Using cached jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
      "Collecting ipython-genutils\n",
      "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting nbclassic>=0.4.7\n",
      "  Using cached nbclassic-1.3.1-py3-none-any.whl (26.2 MB)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting jsonschema>=2.6\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Collecting fastjsonschema>=2.15\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.2.13)\n",
      "Requirement already satisfied: ptyprocess in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.7.0)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.8.4)\n",
      "Collecting attrs>=22.2.0\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Downloading rpds_py-0.26.0-cp39-cp39-macosx_10_12_x86_64.whl (372 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.8/372.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Collecting cffi>=1.0.1\n",
      "  Using cached cffi-1.17.1-cp39-cp39-macosx_10_9_x86_64.whl (182 kB)\n",
      "Requirement already satisfied: pure-eval in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (2.2.0)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/georgiabadlandshaw/.pyenv/versions/3.9.17/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./TransformerBeta_project/requirements.txt (line 14)) (1.3.1)\n",
      "Collecting rfc3986-validator>=0.1.1\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting rfc3339-validator\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Collecting python-json-logger>=2.0.4\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting uri-template\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Collecting isoduration\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Collecting webcolors>=24.6.0\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Collecting jsonpointer>1.13\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting fqdn\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting arrow>=0.15.0\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Collecting types-python-dateutil>=2.8.10\n",
      "  Downloading types_python_dateutil-2.9.0.20250708-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: webencodings, TransformerBeta, sentencepiece, ipython-genutils, fastjsonschema, widgetsnbextension, wheel, websocket-client, webcolors, urllib3, uri-template, types-python-dateutil, torch, tomli, tinycss2, terminado, soupsieve, send2trash, safetensors, rpds-py, rfc3986-validator, rfc3339-validator, regex, qtpy, pyyaml, python-json-logger, pyproject_hooks, pyparsing, pycparser, prometheus-client, pandocfilters, overrides, numpy, mistune, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, jmespath, idna, hf-xet, fqdn, fonttools, entrypoints, defusedxml, cycler, click, chardet, bleach, attrs, scipy, requests, referencing, pandas, matplotlib, jupyter-server-terminals, jupyter-client, cffi, build, botocore, biopython, beautifulsoup4, arrow, torchvision, seaborn, scikit-learn, s3transfer, pip-tools, jsonschema-specifications, isoduration, ipywidgets, huggingface-hub, argon2-cffi-bindings, tokenizers, qtconsole, jupyter-console, jsonschema, boto3, argon2-cffi, transformers, nbformat, nbclient, jupyter-events, bertviz, nbconvert, jupyter-server, notebook-shim, nbclassic, notebook, jupyter\n",
      "\u001b[33m  DEPRECATION: TransformerBeta is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for TransformerBeta ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.3.1\n",
      "    Uninstalling pandas-2.3.1:\n",
      "      Successfully uninstalled pandas-2.3.1\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter_client 8.6.3\n",
      "    Uninstalling jupyter_client-8.6.3:\n",
      "      Successfully uninstalled jupyter_client-8.6.3\n",
      "  Attempting uninstall: biopython\n",
      "    Found existing installation: biopython 1.85\n",
      "    Uninstalling biopython-1.85:\n",
      "      Successfully uninstalled biopython-1.85\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "d2l 0.17.5 requires numpy==1.21.5, but you have numpy 1.23.0 which is incompatible.\n",
      "d2l 0.17.5 requires pandas==1.2.4, but you have pandas 1.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed TransformerBeta-0.0.1 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 attrs-25.3.0 beautifulsoup4-4.13.4 bertviz-1.4.0 biopython-1.81 bleach-6.2.0 boto3-1.39.4 botocore-1.39.4 build-1.2.2.post1 cffi-1.17.1 chardet-4.0.0 click-8.1.8 cycler-0.12.1 defusedxml-0.7.1 entrypoints-0.4 fastjsonschema-2.21.1 fonttools-4.58.5 fqdn-1.5.1 hf-xet-1.1.5 huggingface-hub-0.33.2 idna-2.10 ipython-genutils-0.2.0 ipywidgets-8.1.7 isoduration-20.11.0 jmespath-1.0.1 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 jupyter-1.0.0 jupyter-client-7.4.9 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-pygments-0.3.0 jupyterlab_widgets-3.0.15 kiwisolver-1.4.7 matplotlib-3.5.1 mistune-3.1.3 nbclassic-1.3.1 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-6.5.7 notebook-shim-0.2.4 numpy-1.23.0 overrides-7.7.0 pandas-1.4.3 pandocfilters-1.5.1 pip-tools-6.13.0 prometheus-client-0.22.1 pycparser-2.22 pyparsing-3.2.3 pyproject_hooks-1.2.0 python-json-logger-3.3.0 pyyaml-6.0.2 qtconsole-5.6.1 qtpy-2.4.3 referencing-0.36.2 regex-2024.11.6 requests-2.25.1 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.26.0 s3transfer-0.13.0 safetensors-0.5.3 scikit-learn-1.1.3 scipy-1.8.1 seaborn-0.12.1 send2trash-1.8.3 sentencepiece-0.1.96 soupsieve-2.7 terminado-0.18.1 tinycss2-1.4.0 tokenizers-0.21.2 tomli-2.2.1 torch-1.12.0 torchvision-0.13.0 transformers-4.53.1 types-python-dateutil-2.9.0.20250708 uri-template-1.3.0 urllib3-1.26.20 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 wheel-0.45.1 widgetsnbextension-4.0.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./TransformerBeta_project/requirements.txt ./TransformerBeta_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e3f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"model_M_retrain\" # model directory for loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2330f9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer model loaded: total number of parameters: 44126232\n",
      "Transformer model loaded:: total number of trainable parameters: 44126232\n"
     ]
    }
   ],
   "source": [
    "# do not change the following code of loading the model\n",
    "import torch\n",
    "import torchvision\n",
    "import json\n",
    "import numpy.core.multiarray\n",
    "from collections import OrderedDict\n",
    "from TransformerBeta import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the config\n",
    "with open(\"{}/config.json\".format(model_dir), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Create instances of your encoder and decoder\n",
    "encoder_standard = TransformerEncoder(\n",
    "    config[\"vocab_size\"], config[\"key_size\"], config[\"query_size\"], config[\"value_size\"], config[\"num_hiddens\"], \n",
    "    config[\"norm_shape\"], config[\"ffn_num_input\"], config[\"ffn_num_hiddens\"], config[\"num_heads\"],\n",
    "    config[\"num_layers\"], config[\"dropout\"])\n",
    "decoder_standard = TransformerDecoder(\n",
    "    config[\"vocab_size\"], config[\"key_size\"], config[\"query_size\"], config[\"value_size\"], config[\"num_hiddens\"], \n",
    "    config[\"norm_shape\"], config[\"ffn_num_input\"], config[\"ffn_num_hiddens\"], config[\"num_heads\"],\n",
    "    config[\"num_layers\"], config[\"dropout\"], shared_embedding=encoder_standard.embedding)\n",
    "\n",
    "# Create an instance of your model\n",
    "model_standard = EncoderDecoder(encoder_standard, decoder_standard)\n",
    "model_standard_total_params = sum(p.numel() for p in model_standard.parameters())\n",
    "model_standard_total_trainable_params = sum(p.numel() for p in model_standard.parameters() if p.requires_grad)\n",
    "\n",
    "# Load the model's state_dict\n",
    "state_dict = torch.load(\"{}/model_weights.pth\".format(model_dir), map_location='cpu')\n",
    "\n",
    "# If the state_dict was saved with 'module' prefix due to DataParallel\n",
    "# Remove 'module' prefix if present\n",
    "if list(state_dict.keys())[0].startswith('module'):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove 'module'\n",
    "        new_state_dict[name] = v\n",
    "    state_dict = new_state_dict\n",
    "    \n",
    "model_standard.load_state_dict(state_dict)\n",
    "\n",
    "model_use = model_standard \n",
    "prediction_length = 8\n",
    "device = d2l.try_gpu()\n",
    "\n",
    "# create a txt file to record the results\n",
    "if not os.path.exists('model_prediction'):\n",
    "\tos.mkdir('model_prediction')\n",
    "\n",
    "print('Transformer model loaded: total number of parameters: {}'.format(model_standard_total_params))\n",
    "print('Transformer model loaded:: total number of trainable parameters: {}'.format(model_standard_total_trainable_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8025e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the target sequence from N-terminal to C-terminal\n",
    "task_target = 'PKHNSNRQ'\n",
    "\n",
    "#aa 262-269 | PKHNSNRQ\n",
    "#\n",
    "num_candidates = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529ec2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total candidates sampled: 200\n",
      "number of unique top candidates successfully sampled: 100\n",
      "The first 10 examples candidates are:\n",
      "raw sequence, probability, designed complementary peptide\n",
      "[['LTIETDLL' '3.243484388804063e-05' 'LLDTEITL']\n",
      " ['LSWSITVT' '1.5953499314491637e-05' 'TVTISWSL']\n",
      " ['LTLRIITQ' '1.4417869351746049e-05' 'QTIIRLTL']\n",
      " ['VSWYSETY' '7.872969945310615e-06' 'YTESYWSV']\n",
      " ['LWGAITLR' '7.108681984391296e-06' 'RLTIAGWL']\n",
      " ['IGWCAIVS' '6.978617875574855e-06' 'SVIACWGI']\n",
      " ['LTLTISLR' '4.869420081377029e-06' 'RLSITLTL']\n",
      " ['SWGGLILF' '4.372197508928366e-06' 'FLILGGWS']\n",
      " ['RWVSLTVT' '3.7994664126017597e-06' 'TVTLSVWR']\n",
      " ['LTTQSILG' '2.2957171950110933e-06' 'GLISQTTL']]\n"
     ]
    }
   ],
   "source": [
    "max_iter = 20\n",
    "\n",
    "peptide_candidates = sample_candidates(model_use, task_target, num_candidates, amino_dict, prediction_length + 2, device, max_iter=max_iter)\n",
    "# add a reverse column if antiparallel\n",
    "sythesis_pep = np.array([string[::-1] for string in peptide_candidates[:, 0]])\n",
    "peptide_candidates = np.concatenate((peptide_candidates, sythesis_pep.reshape(-1, 1)), axis=1)\n",
    "\n",
    "print('The first 10 examples candidates are:')\n",
    "print('raw sequence, probability, designed complementary peptide') \n",
    "print(peptide_candidates[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b266215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save peptide candidates as a txt file in a model prediction folder\n",
    "if not os.path.exists('model_prediction'):\n",
    "\tos.mkdir('model_prediction')\n",
    "with open('model_prediction/{}_{}candidates.txt'.format(task_target, num_candidates), 'w') as f:\n",
    "\tfor i in range(len(peptide_candidates)):\n",
    "\t\tf.write(peptide_candidates[i][0] + '\\t' + str(peptide_candidates[i][1]) + '\\t' + str(peptide_candidates[i][2]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c9f01",
   "metadata": {},
   "source": [
    "### Model greedy prediction and random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f40b104e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probability at position 1 is 0.20474985241889954\n",
      "Conditional probability at position 2 is 0.20453570783138275\n",
      "Conditional probability at position 3 is 0.44496893882751465\n",
      "Conditional probability at position 4 is 0.39115068316459656\n",
      "Conditional probability at position 5 is 0.357937753200531\n",
      "Conditional probability at position 6 is 0.18508927524089813\n",
      "Conditional probability at position 7 is 0.41042593121528625\n",
      "Conditional probability at position 8 is 0.36150699853897095\n",
      "Input target sequence is PKHNSNRQ, predicted complementary peptide is LTIETILR\n",
      "Condition on input, predicted probability is 7.164844820484904e-05\n"
     ]
    }
   ],
   "source": [
    "dec_comple_peptide_pred, dec_prob, dec_attention_weight_seq = predict_greedy_single(model_use, task_target, amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e98f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total candidates sampled: 1\n",
      "number of unique top candidates successfully sampled: 1\n",
      "[['NWARLEFT' '2.6198530012067067e-09']]\n"
     ]
    }
   ],
   "source": [
    "peptide_candidates = sample_single_candidate(model_use, task_target, amino_dict, prediction_length + 2, device)\n",
    "print(peptide_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59977012",
   "metadata": {},
   "source": [
    "### Model peptides pair evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5858c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional probability at position 1 is 0.20474985241889954\n",
      "Conditional probability at position 2 is 0.20453570783138275\n",
      "Conditional probability at position 3 is 0.44496893882751465\n",
      "Conditional probability at position 4 is 0.39115068316459656\n",
      "Conditional probability at position 5 is 0.357937753200531\n",
      "Conditional probability at position 6 is 0.18508927524089813\n",
      "Conditional probability at position 7 is 0.41042593121528625\n",
      "Conditional probability at position 8 is 0.36150699853897095\n",
      "Input target sequence is PKHNSNRQ, complementary peptide is LTIETILR\n",
      "Evaluated probability is 7.164844820484904e-05\n"
     ]
    }
   ],
   "source": [
    "complementary_peptide = 'LTIETILR' # note this complementary peptide is in a face to face orientation to the target sequence\n",
    "\n",
    "dec_prob, dec_attention_weight_seq = evaluate_single(model_use, task_target, complementary_peptide, amino_dict, prediction_length + 2, device, save_attention_weights=True, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7142e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_target = 'PKHNSNRQ'\n",
    "num_candidates = 100\n",
    "# number_to_analyze\n",
    "num_analysis = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204fa4b",
   "metadata": {},
   "source": [
    "### Analyze the sampled results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c90e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_dict = np.load('./model_M_retrain/train_data.npy', allow_pickle=True)\n",
    "train_dict = train_dict.tolist()\n",
    "train_list = []\n",
    "for target, value_dict in train_dict.items():\n",
    "    for comp, count in value_dict.items():\n",
    "        train_list.append([target, comp, count])\n",
    "train_array = np.array(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b6185ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read peptide candidates from a txt file in a model prediction folder\n",
    "with open('model_prediction/100_candidates.txt'.format(task_target, num_candidates), 'r') as f:\n",
    "    peptide_candidates = []\n",
    "    for line in f:\n",
    "        peptide_candidates.append(line.strip().split('\\t'))\n",
    "peptide_candidates_all = np.array(peptide_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37d82225",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_candidates_analysis = peptide_candidates_all[:num_analysis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c37d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_net_charge(peptide_list, reference_list=None):\n",
    "    amino_positive = ['R', 'K', 'H']\n",
    "    amino_negative = ['D', 'E']\n",
    "    charge_list = []\n",
    "\n",
    "    for peptide in peptide_list:\n",
    "        charge = 0\n",
    "        for amino_acid in peptide:\n",
    "            if amino_acid in amino_positive:\n",
    "                charge += 1\n",
    "            elif amino_acid in amino_negative:\n",
    "                charge -= 1\n",
    "        charge_list.append(charge)\n",
    "\n",
    "    if reference_list is not None:\n",
    "        reference_charge_list = [calculate_net_charge([ref_seq])[0] for ref_seq in reference_list]\n",
    "        percentile_list = [percentileofscore(reference_charge_list, charge) for charge in charge_list]\n",
    "        return charge_list, percentile_list\n",
    "    else:\n",
    "        return charge_list\n",
    "    \n",
    "kyte_doolittle_scale = {\n",
    "    'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "    'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "def calculate_hydrophobicity(peptide_list, scale, reference_list=None):\n",
    "    hydrophobicity_list = []\n",
    "\n",
    "    for peptide in peptide_list:\n",
    "        hydrophobicity = np.mean([scale[residue] for residue in peptide if residue in scale])\n",
    "        hydrophobicity_list.append(hydrophobicity)\n",
    "\n",
    "    if reference_list is not None:\n",
    "        reference_hydrophobicity_list = calculate_hydrophobicity(reference_list, scale)\n",
    "        percentile_list = [percentileofscore(reference_hydrophobicity_list, hydrophobicity) for hydrophobicity in hydrophobicity_list]\n",
    "        return hydrophobicity_list, percentile_list\n",
    "    else:\n",
    "        return hydrophobicity_list\n",
    "    \n",
    "molecular_weights = {\n",
    "    'A': 89.094,   # Alanine\n",
    "    'R': 174.203,  # Arginine\n",
    "    'N': 132.119,  # Asparagine\n",
    "    'D': 133.104,  # Aspartic acid\n",
    "    'C': 121.154,  # Cysteine\n",
    "    'E': 147.131,  # Glutamic acid\n",
    "    'Q': 146.146,  # Glutamine\n",
    "    'G': 75.067,   # Glycine\n",
    "    'H': 155.156,  # Histidine\n",
    "    'I': 131.175,  # Isoleucine\n",
    "    'L': 131.175,  # Leucine\n",
    "    'K': 146.189,  # Lysine\n",
    "    'M': 149.208,  # Methionine\n",
    "    'F': 165.192,  # Phenylalanine\n",
    "    'P': 115.132,  # Proline\n",
    "    'S': 105.093,  # Serine\n",
    "    'T': 119.120,  # Threonine\n",
    "    'W': 204.228,  # Tryptophan\n",
    "    'Y': 181.191,  # Tyrosine\n",
    "    'V': 117.148,  # Valine\n",
    "}\n",
    "\n",
    "def calculate_molecular_weights(peptide_list, scale, reference_list=None):\n",
    "    molecular_weight_list = []\n",
    "\n",
    "    for peptide in peptide_list:\n",
    "        molecular_weight = np.mean([scale[residue] for residue in peptide if residue in scale])\n",
    "        molecular_weight_list.append(molecular_weight)\n",
    "\n",
    "    if reference_list is not None:\n",
    "        reference_molecular_weight_list = calculate_molecular_weights(reference_list, scale)\n",
    "        percentile_list = [percentileofscore(reference_molecular_weight_list, molecular_weight) for molecular_weight in molecular_weight_list]\n",
    "        return molecular_weight_list, percentile_list\n",
    "    else:\n",
    "        return molecular_weight_list\n",
    "    \n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "def calculate_isoelectric_points(peptide_list, reference_list=None):\n",
    "    isoelectric_point_list = []\n",
    "\n",
    "    for peptide in peptide_list:\n",
    "        analysis = ProteinAnalysis(peptide)\n",
    "        isoelectric_point = analysis.isoelectric_point()\n",
    "        isoelectric_point_list.append(isoelectric_point)\n",
    "\n",
    "    if reference_list is not None:\n",
    "        reference_isoelectric_point_list = calculate_isoelectric_points(reference_list)\n",
    "        percentile_list = [percentileofscore(reference_isoelectric_point_list, isoelectric_point) for isoelectric_point in isoelectric_point_list]\n",
    "        return isoelectric_point_list, percentile_list\n",
    "    else:\n",
    "        return isoelectric_point_list\n",
    "    \n",
    "def calculate_aromaticity(peptide_list, reference_list=None):\n",
    "    aromaticity_list = []\n",
    "\n",
    "    for peptide in peptide_list:\n",
    "        analysis = ProteinAnalysis(peptide)\n",
    "        aromaticity = analysis.aromaticity()\n",
    "        aromaticity_list.append(aromaticity)\n",
    "\n",
    "    if reference_list is not None:\n",
    "        reference_aromaticity_list = calculate_aromaticity(reference_list)\n",
    "        percentile_list = [percentileofscore(reference_aromaticity_list, aromaticity) for aromaticity in aromaticity_list]\n",
    "        return aromaticity_list, percentile_list\n",
    "    else:\n",
    "        return aromaticity_list\n",
    "    \n",
    "def calculate_novelty_scores(peptide_list, reference_list):\n",
    "    novelty_scores = []\n",
    "\n",
    "    for peptide_search in peptide_list:\n",
    "        min_dist = 100\n",
    "        for train_peptide in reference_list:\n",
    "            for j in range(len(peptide_search)):\n",
    "                dist = 0\n",
    "                for k in range(len(peptide_search)):\n",
    "                    if peptide_search[k] != train_peptide[k]:\n",
    "                        dist += 1\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "        novelty_scores.append(min_dist)\n",
    "\n",
    "    return np.array(novelty_scores)\n",
    "\n",
    "def calculate_novelty_scores_and_reference_targets(peptide_list, reference_list, target, target_reference_list):\n",
    "    novelty_scores = []\n",
    "    target_novelty_scores = []\n",
    "\n",
    "    for peptide_search in peptide_list:\n",
    "        min_dist = 100\n",
    "        min_dist_indices = []\n",
    "        for idx, train_peptide in enumerate(reference_list):\n",
    "            dist = 0\n",
    "            for k in range(len(peptide_search)):\n",
    "                if peptide_search[k] != train_peptide[k]:\n",
    "                    dist += 1\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_dist_indices = [idx]\n",
    "            elif dist == min_dist:\n",
    "                min_dist_indices.append(idx)\n",
    "\n",
    "        novelty_scores.append(min_dist)\n",
    "        \n",
    "        min_target_dist = 100\n",
    "        for idx in min_dist_indices:\n",
    "            reference_target = target_reference_list[idx]\n",
    "            target_dist = sum(a != b for a, b in zip(target, reference_target))\n",
    "            if target_dist < min_target_dist:\n",
    "                min_target_dist = target_dist\n",
    "\n",
    "        target_novelty_scores.append(min_target_dist)\n",
    "\n",
    "    return np.array(novelty_scores), np.array(target_novelty_scores)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_output_table(peptide_candidates, peptide_candidates_prob, reference_list, output_file='output_table.xlsx', cluster_labels='', target = None, target_reference_list = None, target_novelty_score = ''):\n",
    "    print('Clustering analysis Done')\n",
    "    ranks = np.arange(1, len(peptide_candidates) + 1) \n",
    "    print('rank analysis Done')\n",
    "    charge, charge_percentile = calculate_net_charge(peptide_candidates, reference_list)\n",
    "    print('Net Charge Analysis Done')\n",
    "    hydrophobicity, hydrophobicity_percentile = calculate_hydrophobicity(peptide_candidates, kyte_doolittle_scale, reference_list)\n",
    "    print('Hydrophobicity Analysis Done')\n",
    "    molecular_weight, molecular_weight_percentile = calculate_molecular_weights(peptide_candidates, molecular_weights, reference_list)\n",
    "    print('Molecular Weight Analysis Done')\n",
    "    isoelectric_point, isoelectric_point_percentile = calculate_isoelectric_points(peptide_candidates, reference_list)\n",
    "    print('Isoelectric Point Analysis Done')\n",
    "    aromaticity, aromaticity_percentile = calculate_aromaticity(peptide_candidates, reference_list)\n",
    "    print('Aromaticity Analysis Done')\n",
    "    if target == None and target_reference_list == None and target_novelty_score == '':\n",
    "        novelty_score = calculate_novelty_scores(peptide_candidates, reference_list)\n",
    "        print('Novelty Score Analysis Done')\n",
    "    else:\n",
    "        novelty_score, target_novelty_score = calculate_novelty_scores_and_reference_targets(peptide_candidates, reference_list, target, target_reference_list)\n",
    "        print('Novelty Score and Target Novelty Score Analysis Done')\n",
    "    # reverse each of the sequence in peptide_candidates\n",
    "    peptide_candidates_synthesis = [peptide[::-1] for peptide in peptide_candidates]\n",
    "\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Cluster Label': cluster_labels,\n",
    "        'Target Sequence': '',\n",
    "        'Designed Complementary Peptide': peptide_candidates,\n",
    "        'Synthesis Complementary Peptide': peptide_candidates_synthesis,\n",
    "        'Probability': peptide_candidates_prob,\n",
    "        'Novelty Score': novelty_score,\n",
    "        'Target Novelty Score': target_novelty_score,\n",
    "        'CamSol Solubility Score': '',\n",
    "        'Net Charge': charge,\n",
    "        'Net Charge Percentile': charge_percentile,\n",
    "        'Hydrophobicity': hydrophobicity,\n",
    "        'Hydrophobicity Percentile': hydrophobicity_percentile,\n",
    "        'Molecular Weight': molecular_weight,\n",
    "        'Molecular Weight Percentile': molecular_weight_percentile,\n",
    "        'Isoelectric Point': isoelectric_point,\n",
    "        'Isoelectric Point Percentile': isoelectric_point_percentile,\n",
    "        'Aromaticity': aromaticity,\n",
    "        'Aromaticity Percentile': aromaticity_percentile\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "461da603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m634.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90328e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering analysis Done\n",
      "rank analysis Done\n",
      "Net Charge Analysis Done\n",
      "Hydrophobicity Analysis Done\n",
      "Molecular Weight Analysis Done\n",
      "Isoelectric Point Analysis Done\n",
      "Aromaticity Analysis Done\n",
      "Novelty Score and Target Novelty Score Analysis Done\n"
     ]
    }
   ],
   "source": [
    "# Generate output table for aa Epitope\n",
    "task_target = \"PKHNSNRQ\"\n",
    "output_file_name = 'model_prediction/output_analysis_{}_100.xlsx'.format(task_target)\n",
    "peptide_candidates = peptide_candidates_analysis[:, 0]\n",
    "peptide_candidates_prob = peptide_candidates_analysis[:, 1]\n",
    "reference_list = train_array[:, 1]\n",
    "target_reference_list = train_array[:, 0]\n",
    "generate_output_table(peptide_candidates, peptide_candidates_prob, reference_list, output_file=output_file_name, cluster_labels='cluster_labels_analysis', target=target, target_reference_list=target_reference_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa05bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TB Local 3.9",
   "language": "python",
   "name": "tblocal3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
